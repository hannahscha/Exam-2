# -*- coding: utf-8 -*-
"""Exam 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-CZUkChicFfvnlQ2Po4Y_PIoR376VjYl

Data Loading
"""

# Import the pandas library for data manipulation and analysis.
import pandas as pd

# Specify the file path to the Excel file.
# Make sure to replace 'path/to/your/file.xlsx' with the actual path to your file.
file_path = '/content/Test2_dataset.xlsx'

# Read the Excel file into a pandas DataFrame.
# The `read_excel()` function is used to load data from an Excel file.
df = pd.read_excel(file_path)

# Display the first few rows of the DataFrame.
# This helps to visualize the data and get a sense of its structure.
print(df.head())

# Print the column names of the DataFrame.
# This shows the names of the variables or features in the dataset.
print(df.columns)

# Get the data types of each column in the DataFrame.
# This is important to understand the nature of the data in each column.
print(df.dtypes)

# Summary:
# This code snippet demonstrates how to load an Excel file into a pandas DataFrame.
# It includes steps to display the first few rows of the data,
# print the column names, and check the data types of each column.
# This information is crucial for understanding the dataset's structure and content.

"""Step 2: Checking for missing data"""

import pandas as pd
# Step 1: Data Loading (same as before)
file_path = '/content/Test2_dataset.xlsx'
df = pd.read_excel(file_path)

# Step 2: Checking for missing data (same as before)
missing_values = df.isnull().sum()
print("Missing values per column:\n", missing_values)

# Step 3: Handling Missing Data

# We'll choose to fill missing values with the mean for numerical columns
# and the mode for categorical columns. This is a common approach
# when dealing with missing values and can provide a reasonable estimate.

# Identify numerical columns
numerical_cols = df.select_dtypes(include=['number']).columns

# Identify categorical columns
categorical_cols = df.select_dtypes(include=['object']).columns

# Iterate through numerical columns and fill missing values with the mean
print("Filling missing values in numerical columns with the mean...")
for col in numerical_cols:
  if df[col].isnull().any():  # Only fill if there are missing values
    df[col].fillna(df[col].mean(), inplace=True)


# Iterate through categorical columns and fill missing values with the mode
print("Filling missing values in categorical columns with the mode...")
for col in categorical_cols:
  if df[col].isnull().any():  # Only fill if there are missing values
    df[col].fillna(df[col].mode()[0], inplace=True)


# Step 4: Verify Missing Values (Optional)
missing_values_after_handling = df.isnull().sum()
print("\nMissing values after handling:\n", missing_values_after_handling)

"""Step 3: Handling Outliers

"""

import matplotlib.pyplot as plt
import seaborn as sns

# Function to detect outliers using the IQR method
def detect_outliers_iqr(data):
  """
  Detects outliers in a dataset using the Interquartile Range (IQR) method.

  Args:
    data: A pandas Series or NumPy array.

  Returns:
    A list of outlier values.
  """
  Q1 = data.quantile(0.25)
  Q3 = data.quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR
  outliers = data[(data < lower_bound) | (data > upper_bound)]
  return outliers.values.tolist()


# Create a dictionary to store outlier information
outlier_summary = {}

# Iterate through each numerical column in the DataFrame
for column in df.select_dtypes(include=['number']).columns:
  # Detect outliers using the IQR method
  outliers = detect_outliers_iqr(df[column])

  # Store outlier information in the dictionary
  outlier_summary[column] = {
      "count": len(outliers),
      "values": outliers
  }

  # Create a boxplot to visualize outliers
  plt.figure(figsize=(4, 3))  # Adjust figure size as needed
  sns.boxplot(x=df[column])
  plt.title(f'Boxplot of {column}')
  plt.show()

  # Create a histogram to visualize outliers
  plt.figure(figsize=(4, 3))  # Adjust figure size as needed
  sns.histplot(df[column], kde=True)
  plt.title(f'Histogram of {column}')
  plt.show()


# Print the summary of outliers
print("Summary of outliers:")
for column, info in outlier_summary.items():
  print(f"{column}:")
  print(f"  Number of outliers: {info['count']}")
  print(f"  Outlier values: {info['values']}")


# Get user input on which outliers to remove
print("\nDo you want to remove any outliers?")
print("1. Remove all outliers")
print("2. Remove specific outliers (enter column names separated by commas)")
print("3. Do not remove any outliers")
choice = input("Enter your choice (1, 2, or 3): ")

if choice == "1":
  # Remove all outliers
  for column in outlier_summary:
    if outlier_summary[column]["count"] > 0:
      # Get indices of outliers
      outlier_indices = df[df[column].isin(outlier_summary[column]["values"])].index
      # Drop rows containing outliers
      df.drop(outlier_indices, inplace=True)
  print("All outliers removed.")

elif choice == "2":
  # Remove specific outliers
  columns_to_remove = input("Enter column names separated by commas: ").split(",")
  for column in columns_to_remove:
    column = column.strip()  # Remove leading/trailing whitespace
    if column in outlier_summary and outlier_summary[column]["count"] > 0:
      # Get indices of outliers
      outlier_indices = df[df[column].isin(outlier_summary[column]["values"])].index
      # Drop rows containing outliers
      df.drop(outlier_indices, inplace=True)
  print("Specific outliers removed.")

elif choice == "3":
  print("No outliers removed.")
else:
  print("Invalid choice.")

# Overview summary
print("\nOverview Summary:")
print("Outliers detected and handled.")
print("Method used to remove outliers: IQR method.")
print("Note: Outlier removal can affect data distribution. Carefully consider the impact on your analysis.")

"""Step 4: Summary Statistics"""

# Calculate summary statistics for numerical columns
numeric_summary = df.describe()

# Display the summary statistics table
print("\nSummary Statistics for Numerical Columns:\n", numeric_summary)

# Calculate the IQR for each numerical column
iqr_values = {}
for column in df.select_dtypes(include=['number']).columns:
  Q1 = df[column].quantile(0.25)
  Q3 = df[column].quantile(0.75)
  IQR = Q3 - Q1
  iqr_values[column] = IQR

# Print the IQR values
print("\nInterquartile Range (IQR) for Numerical Columns:\n", iqr_values)

# Analyze data distribution and identify skews or patterns
for column in df.select_dtypes(include=['number']).columns:
  mean = df[column].mean()
  median = df[column].median()
  std_dev = df[column].std()

  print(f"\nAnalyzing '{column}':")
  print(f"  Mean: {mean:.2f}")
  print(f"  Median: {median:.2f}")
  print(f"  Standard Deviation: {std_dev:.2f}")

  if mean > median:
    print("  Distribution is right-skewed (positively skewed).")
  elif mean < median:
    print("  Distribution is left-skewed (negatively skewed).")
  else:
    print("  Distribution is approximately symmetrical.")

  # Add further analysis based on specific needs, e.g., histograms, boxplots
  # ...

"""Step 5: One-Hot Encoding for Categorical Variables"""

import pandas as pd
# Identify categorical variables
categorical_columns = df.select_dtypes(include=['object']).columns

# Display the list of categorical variables to the user
print("Categorical variables found in the dataset:")
print(categorical_columns)

# Confirm data types to avoid misinterpreting numerical data as categorical
print("\nData types of each column:")
print(df.dtypes)

# Explain the purpose of one-hot encoding
print("\nOne-hot encoding is used to convert categorical variables into numerical format suitable for analysis.")
print("This involves creating new binary columns for each unique category in the original column.")
print("This allows machine learning algorithms to understand and utilize categorical data effectively.")

# Apply one-hot encoding
df_encoded = pd.get_dummies(df, columns=categorical_columns)

# Display the updated DataFrame with encoded columns
print("\nDataFrame after one-hot encoding:")
print(df_encoded.head())

# Explain the changes to the dataset
print("\nThe dataset has been transformed by adding new columns for each category.")
print("Original categorical columns have been replaced with numerical representations.")
print("This allows for better analysis and model building.")

"""Step 6: Checking for redundant columns"""

# Identify columns with constant values
constant_columns = [col for col in df_encoded.columns if df_encoded[col].nunique() <= 1]

# Print columns with constant values
if constant_columns:
  print("\nColumns with constant values:")
  print(constant_columns)
  print("These columns provide no information for analysis and can be removed.")
else:
  print("\nNo columns with constant values found.")

# Identify columns with duplicate information
duplicate_columns = []
for i in range(len(df_encoded.columns)):
  for j in range(i + 1, len(df_encoded.columns)):
    if df_encoded.iloc[:, i].equals(df_encoded.iloc[:, j]):
      duplicate_columns.append((df_encoded.columns[i], df_encoded.columns[j]))

# Print columns with duplicate information
if duplicate_columns:
  print("\nColumns with duplicate information:")
  for col1, col2 in duplicate_columns:
    print(f"Columns '{col1}' and '{col2}' have identical values.")
  print("These columns contain redundant information and one of them can be removed.")
else:
  print("\nNo columns with duplicate information found.")

# Identify irrelevant columns (this requires domain knowledge)
# This is a placeholder for a more sophisticated method
irrelevant_columns = []  # This list would be populated based on domain knowledge
# Example: irrelevant_columns = ['column_name1', 'column_name2']

# Print irrelevant columns
if irrelevant_columns:
  print("\nIrrelevant columns:")
  print(irrelevant_columns)
  print("These columns are not relevant to the analysis and can be removed.")
else:
  print("\nNo irrelevant columns identified (requires domain knowledge).")

# Ask user if they want to remove redundant columns
print("\nDo you want to remove any redundant columns?")
print("1. Remove all redundant columns")
print("2. Remove specific columns (enter column names separated by commas)")
print("3. Do not remove any columns")
choice = input("Enter your choice (1, 2, or 3): ")

if choice == "1":
  # Remove all redundant columns
  columns_to_remove = constant_columns + [col1 for col1, col2 in duplicate_columns] + irrelevant_columns
  df_encoded.drop(columns=columns_to_remove, inplace=True)
  print("All redundant columns removed.")

elif choice == "2":
  # Remove specific columns
  columns_to_remove = input("Enter column names separated by commas: ").split(",")
  for column in columns_to_remove:
    column = column.strip()  # Remove leading/trailing whitespace
    if column in df_encoded.columns:
      df_encoded.drop(columns=column, inplace=True)
  print("Specific columns removed.")

elif choice == "3":
  print("No redundant columns removed.")
else:
  print("Invalid choice.")

# Summary
print("\nOverview Summary:")
print("Redundant columns identified and handled.")
print("Methods used to identify redundancies:")
print("- Columns with constant values")
print("- Columns with duplicate information")
print("- Irrelevant columns (requires domain knowledge)")
print("Note: Removing redundant columns can improve data efficiency and analysis.")

"""Step 7: Visualizations - General"""

# prompt: Create visualizations (scatter plots, histograms, box plots) to identify trends and relationships between variables, be able to copy to anoother data set to use the same code for analysis

import matplotlib.pyplot as plt
# Step 8: Visualizing Data Relationships

# Function to create scatter plots for pairs of variables
def create_scatter_plots(df, variable_pairs):
  """
  Creates scatter plots to visualize relationships between pairs of variables.

  Args:
    df: The pandas DataFrame containing the data.
    variable_pairs: A list of tuples, where each tuple contains two variable names.
  """
  for var1, var2 in variable_pairs:
    plt.figure(figsize=(6, 4))  # Adjust figure size as needed
    plt.scatter(df[var1], df[var2])
    plt.xlabel(var1)
    plt.ylabel(var2)
    plt.title(f"Scatter Plot: {var1} vs. {var2}")
    plt.show()

# Function to create histograms for individual variables
def create_histograms(df, variables):
  """
  Creates histograms to visualize the distribution of individual variables.

  Args:
    df: The pandas DataFrame containing the data.
    variables: A list of variable names.
  """
  for variable in variables:
    plt.figure(figsize=(6, 4))  # Adjust figure size as needed
    plt.hist(df[variable], bins=10)  # You can adjust the number of bins
    plt.xlabel(variable)
    plt.ylabel("Frequency")
    plt.title(f"Histogram of {variable}")
    plt.show()

# Function to create box plots for individual variables
def create_box_plots(df, variables):
  """
  Creates box plots to visualize the distribution and potential outliers of individual variables.

  Args:
    df: The pandas DataFrame containing the data.
    variables: A list of variable names.
  """
  for variable in variables:
    plt.figure(figsize=(6, 4))  # Adjust figure size as needed
    sns.boxplot(x=df[variable])
    plt.xlabel(variable)
    plt.title(f"Box Plot of {variable}")
    plt.show()

# Select the variables you want to visualize relationships between
# Replace with your actual variable names
variables_for_scatter = [('Reaction Time', 'Ratio of CH4 in Feed'), ('CH4 Conversion', 'CO2 Conversion')]

# Select the variables for histograms and box plots
variables_for_histograms = ['CH4 Conversion', 'CO2 Conversion','Syngas_Ratio']
variables_for_boxplots = ['CH4 Conversion', 'CO2 Conversion','Syngas_Ratio']


# Create visualizations
create_scatter_plots(df_encoded, variables_for_scatter)
create_histograms(df_encoded, variables_for_histograms)
create_box_plots(df_encoded, variables_for_boxplots)

# Now you can copy this code and paste it in a notebook for a new dataset.
# Remember to replace the DataFrame name 'df_encoded' and adjust the variable names as needed.

print("\nVisualizations created to identify trends and relationships between variables.")

"""Step 8: Visualizing Data Relationship Based on Correlation Values"""

import matplotlib.pyplot as plt
# Identify numerical and categorical variables
numerical_columns = df_encoded.select_dtypes(include=['number']).columns
categorical_columns = df_encoded.select_dtypes(include=['object']).columns

# Create a table with relationships between variables
print("\nRelationships between variables (order of magnitude):")
relationships = []
for i in range(len(df_encoded.columns)):
  for j in range(i + 1, len(df_encoded.columns)):
    col1 = df_encoded.columns[i]
    col2 = df_encoded.columns[j]
    correlation = df_encoded[col1].corr(df_encoded[col2])
    relationships.append((col1, col2, abs(correlation)))

# Sort relationships by correlation strength
relationships.sort(key=lambda x: x[2], reverse=True)

# Display the relationships in a numbered table
print("Relationships between Variables (Top 1000):")
for i, (col1, col2, correlation) in enumerate(relationships[:1000]):
  print(f"{i+1}. {col1} & {col2}: {correlation:.4f}")

# Get user input for visualization range
print("\nWhich relationships do you want to visualize?")
start_range = int(input("Enter the starting number: "))
end_range = int(input("Enter the ending number: "))

# Visualize selected relationships
for i in range(start_range - 1, end_range):
  col1, col2, correlation = relationships[i]
  print(f"\nVisualizing relationship between {col1} and {col2}:")

  if col1 in numerical_columns and col2 in numerical_columns:
    # Scatter plot for continuous variables
    plt.figure(figsize=(6, 4))
    sns.regplot(x=df_encoded[col1], y=df_encoded[col2], line_kws={'color': 'red'})
    plt.title(f"{col1} vs {col2}")
    plt.xlabel(col1)
    plt.ylabel(col2)
    plt.show()

  elif col1 in categorical_columns and col2 in categorical_columns:
    # Bar/count plot for categorical variables
    plt.figure(figsize=(8, 6))
    sns.countplot(x=df_encoded[col1], hue=df_encoded[col2])
    plt.title(f"{col1} vs {col2}")
    plt.xlabel(col1)
    plt.ylabel("Count")
    plt.show()

  else:
    # Pair plot to show relationships across multiple features
    # (if identified)
    # Example: sns.pairplot(df_encoded[['col1', 'col2', 'col3']])
    print("Consider using pair plot for relationships across multiple features.")

# Explain relationships and patterns
print("\nBased on the visualizations and correlation analysis:")
for i in range(start_range - 1, end_range):
  col1, col2, correlation = relationships[i]
  if correlation > 0.7:
    print(f"  - A strong positive correlation exists between {col1} and {col2}.")
    print(f"    As {col1} increases, {col2} tends to increase as well.")
  elif correlation < -0.7:
    print(f"  - A strong negative correlation exists between {col1} and {col2}.")
    print(f"    As {col1} increases, {col2} tends to decrease.")
  else:
    print(f"  - The relationship between {col1} and {col2} is moderate or weak.")

# Identify most influential variables on CH4 Conversion

CH4_Conversion_correlations = []
for col in df_encoded.columns:
  if col != 'CH4 Conversion':
    correlation = df_encoded['CH4 Conversion'].corr(df_encoded[col])
    CH4_Conversion_correlations.append((col, abs(correlation)))

# Identify most influential variables on CO2 Conversion

CO2_Conversion_correlations = []
for col in df_encoded.columns:
  if col != 'CO2 Conversion':
    correlation = df_encoded['CO2 Conversion'].corr(df_encoded[col])
    CO2_Conversion_correlations.append((col, abs(correlation)))

 # Identify most influential variables on Syngas Ratio

Syngas_Ratio_correlations = []
for col in df_encoded.columns:
  if col != 'Syngas_Ratio':
    correlation = df_encoded['Syngas_Ratio'].corr(df_encoded[col])
    Syngas_Ratio_correlations.append((col, abs(correlation)))

# Sort by correlation strength
CH4_Conversion_correlations.sort(key=lambda x: x[1], reverse=True)
CO2_Conversion_correlations.sort(key=lambda x: x[1], reverse=True)
Syngas_Ratio_correlations.sort(key=lambda x: x[1], reverse=True)

#CH4
# Display the most influential variables
print("\nMost influential variables on CH4 Conversion:")
for col, correlation in CH4_Conversion_correlations[:5]:  # Show top 5
  print(f"  - {col}: {correlation:.2f}")

# Explain the influence of variables on CH4 Conversion
print("\nBased on the correlation analysis:")
for col, correlation in CH4_Conversion_correlations[:5]:
  if correlation > 0.7:
    print(f"  - {col} has a strong positive influence on CH4 Conversion.")
    print(f"    Higher values of {col} tend to result in higher CH4 Conversion.")
  elif correlation < -0.7:
    print(f"  - {col} has a strong negative influence on CH4 Conversion.")
    print(f"    Higher values of {col} tend to result in lower CH4 Conversion.")
  else:
    print(f"  - The influence of {col} on CH4 Conversion is moderate or weak.")

#CO2
# Display the most influential variables
print("\nMost influential variables on CO2 Conversion:")
for col, correlation in CO2_Conversion_correlations[:5]:  # Show top 5
  print(f"  - {col}: {correlation:.2f}")

# Explain the influence of variables on CO2 Conversion
print("\nBased on the correlation analysis:")
for col, correlation in CO2_Conversion_correlations[:5]:
  if correlation > 0.7:
    print(f"  - {col} has a strong positive influence on CO2 Conversion.")
    print(f"    Higher values of {col} tend to result in higher CO2 Conversion.")
  elif correlation < -0.7:
    print(f"  - {col} has a strong negative influence on CO2 Conversion.")
    print(f"    Higher values of {col} tend to result in lower CO2 Conversion.")
  else:
    print(f"  - The influence of {col} on CO2 Conversion is moderate or weak.")

#syngas
# Display the most influential variables
print("\nMost influential variables on Syngas Ratio:")
for col, correlation in Syngas_Ratio_correlations[:5]:  # Show top 5
  print(f"  - {col}: {correlation:.2f}")

# Explain the influence of variables on Syngas Ratio
print("\nBased on the correlation analysis:")
for col, correlation in Syngas_Ratio_correlations[:5]:
  if correlation > 0.7:
    print(f"  - {col} has a strong positive influence on Syngas Ratio.")
    print(f"    Higher values of {col} tend to result in higher Syngas Ratio.")
  elif correlation < -0.7:
    print(f"  - {col} has a strong negative influence on Syngas Ratio.")
    print(f"    Higher values of {col} tend to result in lower Syngas Ratio.")
  else:
    print(f"  - The influence of {col} on Syngas Ratio is moderate or weak.")